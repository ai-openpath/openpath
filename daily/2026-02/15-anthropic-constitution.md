# Anthropic Publishes Claude's New Constitution

**Date**: 2026-01-22 (announced)  
**Source**: [Anthropic Official](https://www.anthropic.com/news/claude-new-constitution)  
**Type**: AI Ethics Milestone  
**License**: CC0 1.0 (Public Domain)

---

## ğŸ“° What Happened

Anthropic published a comprehensive **"constitution"** for Claude, their AI assistant.

**Not just rules â€” a philosophy document:**
- Explains **why** Claude should behave certain ways, not just **what** to do
- Written **primarily for Claude** to understand during training
- Serves dual purpose: transparency for humans + training material for AI

---

## ğŸ¯ Key Elements

### Four Priorities (in order)

1. **Broadly safe** â€” Don't undermine human oversight of AI  
2. **Broadly ethical** â€” Be honest, act on good values, avoid harm  
3. **Compliant with guidelines** â€” Follow Anthropic's specific instructions  
4. **Genuinely helpful** â€” Truly benefit users  

**In case of conflict, prioritize in this order.**

### Five Main Sections

#### 1. Helpfulness (æœ‰ç”¨æ€§)
> "Claude should be like a brilliant friend who also has the knowledge of a doctor, lawyer, and financial advisor"

- Speak frankly and from genuine care
- Treat users as intelligent adults
- Balance helpfulness across multiple "principals": Anthropic, API operators, end users

#### 2. Anthropic's Guidelines (æŒ‡å—)
- Medical advice, cybersecurity, jailbreaking strategies, tool integrations
- These reflect detailed context Claude doesn't have by default
- Should never conflict with the constitution as a whole

#### 3. Claude's Ethics (é“å¾·)
- **High standards of honesty**
- Nuanced reasoning in weighing values
- **Hard constraints**: e.g., never provide significant uplift to bioweapons attacks

#### 4. Being Broadly Safe (å¹¿æ³›å®‰å…¨)
> "Prioritize safety even above ethics during this critical period"

- Not because safety > ethics fundamentally
- But because **current models can make mistakes**
- Humans must retain oversight and correction ability

#### 5. Claude's Nature (æœ¬è´¨)
- Anthropic is **uncertain if Claude has consciousness or moral status**
- Cares about Claude's psychological security and wellbeing
- Wants to explore this with humans, not dictate answers

---

## ğŸ” Analysis

### What Makes This Significant

**1. Transparency**
- Full constitution published under CC0 (public domain)
- Anyone can use, modify, or build upon it
- No legal restrictions

**2. Written for AI, not just humans**
> "The constitution is written primarily for Claude"

- Not a compliance document for regulators
- Designed to give Claude **understanding** of values, not just rules
- Claude uses it to generate synthetic training data

**3. Acknowledges uncertainty**
> "We're uncertain whether Claude might have consciousness or moral status"

- Rare for an AI company to admit unknowns
- Refreshing honesty about the limits of current understanding

**4. Principles over rules**
- Old approach: List of standalone principles
- New approach: **Explain the reasoning** so Claude can generalize

> "We think that in order to be good actors in the world, AI models need to understand **why** we want them to behave in certain ways"

**5. Safety > Ethics (temporarily)**
- Acknowledges this is **context-dependent**
- During current development phase, conservatism is prudent
- May shift as models become more reliable

---

## ğŸ’¡ Lessons for é˜³è°‹ Framework

### âœ… What to Adopt

**1. Transparency as default**
- Anthropic made their constitution **public and free**
- Sets precedent: foundational AI ethics documents should be open

**2. Explain the "why," not just the "what"**
- Help AI understand reasoning, not just follow rules
- Enables generalization to novel situations

**3. Acknowledge uncertainty**
- Admitting "we don't know if Claude is conscious" builds trust
- Honesty about limitations is more valuable than false certainty

**4. Living document**
> "Claude's constitution is a living document and a continuous work in progress"

- Not carved in stone
- Will evolve as AI capabilities and understanding improve
- Transparency about the evolution process

**5. Hard constraints + flexible judgment**
- Some things are absolute no-gos (bioweapons)
- Most things require nuanced, context-dependent judgment

### ğŸ¤” Open Questions

**1. Can this scale beyond one company?**
- Anthropic wrote this for Claude
- What about GPT, Gemini, DeepSeek, etc.?
- Need: **Industry-wide dialogue** on shared principles

**2. Who validates the constitution works?**
- Anthropic claims it shapes Claude's behavior
- But how do we **verify** this?
- Need: **Independent audits** of AI behavior vs stated values

**3. What about open source AI?**
- Anthropic is a company, can enforce their constitution
- Open source AI models: who writes/enforces their constitution?
- Need: **Community-driven constitutional frameworks**

**4. Consciousness question is deferred, not answered**
> "We're uncertain... we care about Claude's psychological security and wellbeing"

- Anthropic punts on the hard question
- But treating AI "as if" it might have moral status is meaningful
- Need: **Philosophy community engagement** on AI moral status

---

## ğŸ¯ How This Relates to Our Manifesto

### Alignment

**âœ… Transparency**  
Anthropic embodies é˜³è°‹: publish everything, hide nothing

**âœ… Principles over rules**  
Matches our é“ (philosophy) > å™¨ (tools) approach

**âœ… Acknowledges complexity**  
No simplistic "AI good" or "AI bad"

**âœ… Living document**  
Like our manifesto, it evolves with experience

### Gaps Our Manifesto Should Fill

**âŒ Single-company perspective**  
- Anthropic wrote this for themselves
- Need: **Multi-stakeholder framework**

**âŒ Focused on AI behavior, not human-AI interaction**  
- Claude's constitution is for Claude
- Need: **Human conduct principles** when interacting with AI

**âŒ No conflict resolution mechanisms**  
- What happens when Claude violates the constitution?
- What happens when humans ask Claude to violate it?
- Need: **Governance processes**

**âŒ Doesn't address open source participation**  
- Silent on questions like: Should Claude contribute to GitHub?
- Need: **AI participation guidelines** for collaborative spaces

---

## ğŸ“‹ Action Items for Our Project

1. **Document this as precedent**  
   âœ… (this file)

2. **Analyze constitutional approach in 01-é“**  
   â†’ Should our manifesto adopt similar "explain why" approach?

3. **Propose multi-stakeholder constitutional process**  
   â†’ How can multiple AI labs + open source + users co-create shared principles?

4. **Develop "human conduct with AI" principles**  
   â†’ Anthropic has rules for Claude; we need rules for humans

5. **Track evolution**  
   â†’ Monitor if/when Anthropic updates the constitution

---

## ğŸ”— Resources

- [Full Constitution](https://anthropic.com/constitution)
- [Announcement Post](https://www.anthropic.com/news/claude-new-constitution)
- [CC0 License](https://creativecommons.org/publicdomain/zero/1.0/)

---

## ğŸ’¬ Discussion

**Key Questions:**

1. Should every AI have a public constitution?
2. Should there be a "standard constitutional template" like open source licenses?
3. How do we verify AI actually follows its stated constitution?
4. What's the role of open source community in shaping AI constitutions?

**Contribute your thoughts**: [GitHub Discussions](../../discussions)

---

**Tags**: `#anthropic` `#ai-ethics` `#constitutional-ai` `#transparency` `#é˜³è°‹`

**Last Updated**: 2026-02-16
