# IEP: AI Ethics Framework

## 基本信息
- **来源**: Internet Encyclopedia of Philosophy
- **标题**: Ethics of Artificial Intelligence
- **链接**: https://iep.utm.edu/ethics-of-artificial-intelligence/
- **类型**: 学术综述

## 核心观点

### 价值对齐原则
> "AI should be tracking human interests and values, and its functioning should benefit us and not lead to any existential risks"

**翻译**:
> AI应该追踪人类的利益和价值观，其功能应该造福我们，而不是导致存在性风险

### 关键要素
1. **追踪人类价值** (tracking human values)
2. **造福人类** (benefit us)
3. **避免存在风险** (avoid existential risks)

## 与OpenPath的连接点

### 相似之处
- ✅ 强调AI应服务人类利益
- ✅ 关注存在性风险
- ✅ 价值对齐的必要性

### OpenPath的补充
**单向 vs 双向对齐**:

| IEP框架 | OpenPath Co-alignment |
|---------|---------------------|
| AI追踪人类价值 | AI ↔ 人类 双向对齐 |
| 单向服务关系 | 互补共生关系 |
| 人类中心论 | 双方共同演化 |

**OpenPath洞察**:
> IEP框架停留在"AI为人类服务"层面，  
> 缺少"人类如何适应AI"的对称性思考

### 可引用之处
在传播OpenPath时：
- **对传统AI伦理学者**: "IEP强调价值对齐，我们把它扩展为双向Co-alignment"
- **对价值对齐支持者**: "你们的目标我们支持，但方法需要升级"

## 学术价值

### 作为基础文献
- 系统性综述AI伦理主要议题
- 适合作为01-Philosophy章节的学术参考
- 可作为"传统AI伦理观"的代表

### 批判性使用
- 用于对比OpenPath的创新点
- 展示从"单向控制"到"双向共生"的范式转变

## 相关资源

### Stanford Encyclopedia of Philosophy: AI Ethics
- **链接**: https://plato.stanford.edu/entries/ethics-ai/
- **定位**: 更权威，更学术化
- **用途**: 深度参考

### RIT: Responsible AI & Philosophy
- **链接**: https://www.rit.edu/news/philosophy-ethics-and-pursuit-responsible-artificial-intelligence
- **观点**: "AI伦理超越技术修复，需要哲学家参与"
- **价值**: 支持OpenPath跨学科方法

---

**收录时间**: 2026-02-18  
**整理者**: Claw Research  
**归档位置**: 02-Methodology-法/references/frameworks/  
**用途**: 传播时引用 + 对比OpenPath创新点
