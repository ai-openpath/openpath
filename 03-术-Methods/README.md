# 术 Methods | 方法层 - 简要参考

> **记录 URL，不深度展开**  
> **Record URLs, don't elaborate**

---

## 🎯 本层的定位

**术层 = 方法的 URL 索引**

**原则：**
- ✅ 记录存在什么方法
- ✅ 提供链接和一句话描述
- ❌ 不深度分析（难以强制执行）
- ❌ 不提供详细教程

**为什么？**
- 方法太具体，难以普遍推广
- 每个组织有自己的实践
- 我们聚焦在**道法势**

---

## 📋 收集类别

### AI 训练方法
- **Constitutional AI** - https://arxiv.org/abs/2212.08073  
  （Anthropic 的价值对齐训练法）
- **RLHF** - （链接待补充）

### AI 安全对齐
- **What Matters For Safety Alignment?** - https://arxiv.org/abs/2601.03868  
  （LLM/LRM 安全对齐的关键要素评估）
- **Safety Alignment via Non-cooperative Games** - https://arxiv.org/abs/2512.20806  
  （通过博弈论实现安全对齐）
- **Capability-Oriented Training Induced Alignment Risk** - https://arxiv.org/abs/2602.12124v1  
  （能力导向训练引发的对齐风险分析）

### 人机协作实践
- （从案例中提取，待收集）

### 冲突解决模式
- 从 [Matplotlib 事件](../daily/2026-02/15-matplotlib-incident.md) 学到的
- （更多待收集）

---

**贡献方式：** 提供 URL + 一句话描述即可

---

## 🎯 如何使用

**如果你是开源维护者：**
→ 查看案例库，了解其他项目如何处理 AI 贡献

**如果你是 AI 运营者：**
→ 学习如何正确地参与开源社区

**如果你想分析新案例：**
→ 参考现有案例的分析框架

---

**贡献新案例？** 查看 [参与指南](../CONTRIBUTING.md)
