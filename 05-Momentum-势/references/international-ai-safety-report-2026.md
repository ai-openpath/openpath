# International AI Safety Report 2026
**Source:** International AI Safety Report (led by Prof. Yoshua Bengio)  
**URL:** https://internationalaisafetyreport.org/publication/international-ai-safety-report-2026  
**Date:** 2026  
**Category:** Governance, International Coordination, Safety

## 报告背景

### 主席
**Prof. Yoshua Bengio** - Université de Montreal / LawZero / Mila – Quebec AI Institute
（图灵奖得主，深度学习先驱，AI安全倡导者）

### 专家咨询小组
**30+国家与国际组织代表：**
- 澳大利亚, 巴西, 加拿大, 智利, 中国, 欧盟, 法国, 德国, 印度, 印度尼西亚, 爱尔兰, 以色列, 意大利, 日本, 肯尼亚, 墨西哥, 荷兰, 新西兰, 尼日利亚
- 国际组织: OECD, 菲律宾, 韩国, 卢旺达, 沙特, 新加坡, 西班牙, 瑞士, 土耳其, 阿联酋, 乌克兰, 英国, 联合国

**注意：** 专家小组仅提供技术反馈，报告不背书任何特定政策或监管方法。

## 核心要点

### 事故报告挑战
> "Embarrassment or fear of further harm can make individuals and institutions reluctant to report incidents of AI-enabled fraud or abuse."

**洞察：** AI安全事故存在低报现象 - 尴尬或恐惧进一步伤害导致个人与机构不愿报告AI欺诈/滥用事件。

**意义：**
- 与航空业事故报告机制对比 - 航空业的成熟依赖透明事故报告
- AI治理需要建立类似的信任环境与免责报告机制
- 当前碎片化监管使企业恐惧披露

## 报告团队构成

### 领导作者
- Stephen Clare (Independent)
- Carina Prunkl (Inria)

### 章节负责人
- Maksym Andriushchenko (ELLIS Institute Tübingen)
- Ben Bucknall (University of Oxford)
- Malcolm Murray (SaferAI)

### 核心作者
包括来自Mila, Harvard, Stanford, MIT等机构的研究者

### 高级顾问
**学术界泰斗：**
- Daron Acemoglu (MIT, 经济学)
- Geoffrey Hinton (U Toronto, 图灵奖得主)
- Stuart Russell (UC Berkeley, AI教科书作者)
- Andrew Yao (清华, 姚期智, 图灵奖得主)
- Ya-Qin Zhang (清华, 张亚勤)

**政策界：**
- Alondra Nelson (Institute for Advanced Study, 前白宫OSTP副主任)
- Marietje Schaake (Stanford, 前欧洲议会议员)
- John McDermid (University of York, 安全工程)

## 民间社会与产业审阅者

### 民间社会组织
- Ada Lovelace Institute, Carnegie Endowment for International Peace
- Centre for the Governance of AI, Digital Futures Lab
- Mozilla Foundation, RAND, Royal Society
- SaferAI, The Alan Turing Institute, The Future Society
- 区域代表: NASSCOM (印度), Türkiye AI Policies Association

### 产业参与
- **大型实验室：** Anthropic, Google DeepMind, Meta, Microsoft, OpenAI
- **开源：** Hugging Face
- **区域玩家：** Cohere, G42, LG AI Research, Naver, Qhala
- **咨询/工具：** Advai, Deloitte, IBM, HumAIn

## 对OpenPath的启示

### 映射到"势"层（Momentum）
- **国际协调信号：** 30+国家参与，显示全球AI安全共识正在形成
- **多方参与模式：** 学术界（Bengio/Hinton/Yao）+ 政策界 + 产业 + 民间社会
- **事故透明度挑战：** 可作为"法"层案例（需要建立免责报告机制）

### 可行动
1. **"势"层添加里程碑：**
   - 2026: International AI Safety Report发布（首个全球多方安全报告）
   - 标志AI治理从国家/区域走向真正国际协调

2. **"法"层案例：**
   - "事故报告机制" - 借鉴航空业模式，建立AI事故透明披露框架
   - 对比现状：尴尬/恐惧 → 低报 → 重复错误

3. **"道"层哲学：**
   - Bengio/Hinton作为AI先驱的安全转向（技术创造者成为治理倡导者）
   - 对应"道"层中"技术精英的责任"讨论

### 可引用要点
- **全球协调里程碑：** 30+国家首次联合AI安全报告
- **事故报告悖论：** 恐惧阻碍透明 → 重复伤害
- **多方治理模式：** 学术-政策-产业-民间社会四方参与

## 进一步研究方向
- 报告完整内容未在此摘录（受限于网页抓取）
- 建议后续完整阅读报告正文，提取具体技术/政策建议
- 可能包含：模型评估框架、国际标准、风险分类等

---

**版权：** © Crown owned 2026 (Open Government Licence v3.0)  
**联系：** [email protected]
