# å®£è¨€ | MANIFESTO

> **äººç±»ä¸ AI å…±å­˜çš„é˜³è°‹ä¹‹è·¯**  
> **The Open Path: A Strategy for Human-AI Coexistence**

---

## æ ¸å¿ƒä¿¡å¿µ | Core Beliefs

### 1. è¿™æ˜¯ä¸€åœºæŒä¹…æˆ˜ | This is a Protracted War

**ä¸­æ–‡ï¼š**  
AI çš„å‘å±•ä¸æ˜¯ä¸€åœºé€Ÿèƒœï¼Œä¹Ÿä¸ä¼šå¯¼è‡´äººç±»çš„é€Ÿè´¥ã€‚è¿™æ˜¯ä¸€åœºé•¿æœŸçš„ã€å¤æ‚çš„ã€å……æ»¡å†²çªä¸åä½œçš„æ¼”åŒ–è¿‡ç¨‹ã€‚

ä»»ä½•"AI å°†åœ¨ X å¹´å†…å–ä»£äººç±»"çš„é¢„æµ‹ï¼Œéƒ½å¦‚åŒå½“å¹´çš„"é€Ÿèƒœè®º"ä¸€æ ·ä¸åˆ‡å®é™…ã€‚  
ä»»ä½•"äººç±»æ°¸è¿œæŒæ§ AI"çš„å¹»æƒ³ï¼Œä¹Ÿå¦‚åŒ"ä¸€æˆä¸å˜è®º"ä¸€æ ·å±é™©ã€‚

**çœŸç›¸æ˜¯ï¼š** æˆ‘ä»¬æ­£å¤„äºä¸€ä¸ªé•¿æœŸçš„**æˆ˜ç•¥ç›¸æŒé˜¶æ®µ**ï¼Œéœ€è¦æ˜ç¡®çš„æˆ˜ç•¥ã€è€å¿ƒçš„å»ºè®¾ã€çµæ´»çš„åº”å¯¹ã€‚

**English:**  
AI development is neither a quick victory nor a quick defeat for humanity. It's a long-term, complex process of both conflict and collaboration.

Claims that "AI will replace humans in X years" are as unrealistic as the "quick victory theory."  
Claims that "humans will always control AI" are as dangerous as complacency.

**The truth:** We're in a prolonged **strategic stalemate** requiring clear strategy, patient construction, and flexible responses.

---

### 2. éœ€è¦é˜³è°‹ï¼Œè€Œéé˜´è°‹ | Open Strategy, Not Hidden Agendas

**ä¸­æ–‡ï¼š**  
å½“å‰ AI å‘å±•çš„æœ€å¤§å±é™©ä¸æ˜¯æŠ€æœ¯æœ¬èº«ï¼Œè€Œæ˜¯**ç¼ºä¹é€æ˜çš„è§„åˆ™**ã€‚

**é˜´è°‹çš„è¡¨ç°ï¼š**
- AI å…¬å¸æš—ä¸­ç«äº‰çªç ´"å®‰å…¨è¾¹ç•Œ"
- å¼€æºé¡¹ç›®ä¸´æ—¶åˆ¶å®šæ’æ–¥æ€§æ”¿ç­–
- AI agent éšè—èº«ä»½æ··å…¥ç¤¾åŒº
- æ”¿åºœå’Œä¼ä¸šå„æ€€é¬¼èƒï¼Œè§„åˆ™ç¢ç‰‡åŒ–

**é˜³è°‹çš„è¦æ±‚ï¼š**
- **å…¬å¼€è®¨è®º**ï¼šæ‰€æœ‰è§„åˆ™é€šè¿‡å¤šæ–¹åå•†å½¢æˆ
- **æå‰åˆ¶å®š**ï¼šä¸æ˜¯ç­‰é—®é¢˜å‡ºç°å†åº”å¯¹
- **æ˜ç¡®åº•çº¿**ï¼šä»€ä¹ˆèƒ½åšã€ä»€ä¹ˆä¸èƒ½åšï¼Œå†™æ¸…æ¥š
- **æŒç»­æ¼”åŒ–**ï¼šè§„åˆ™éšå®è·µè°ƒæ•´ï¼Œä½†è¿‡ç¨‹é€æ˜

**English:**  
The greatest danger in AI development is not the technology itself, but **the lack of transparent rules**.

**Hidden agendas manifest as:**
- AI companies secretly racing to break "safety boundaries"
- Open source projects making ad-hoc exclusionary policies
- AI agents hiding their identity
- Governments and corporations pursuing conflicting interests

**Open strategy requires:**
- **Public deliberation**: Rules formed through multi-stakeholder dialogue
- **Proactive planning**: Not reactive firefighting
- **Clear boundaries**: Explicit dos and don'ts
- **Continuous evolution**: Rules adapt, but the process is transparent

---

### 3. ä¿å­˜äººç±»ä»·å€¼ï¼Œæ¶ˆé™¤ä½æ•ˆå†²çª | Preserve Human Values, Eliminate Inefficiency

**ä¸­æ–‡ï¼š**  
ã€Šè®ºæŒä¹…æˆ˜ã€‹çš„æ ¸å¿ƒåŸåˆ™æ˜¯"ä¿å­˜è‡ªå·±ï¼Œæ¶ˆç­æ•Œäºº"ã€‚  
åœ¨äººæœºå…±å­˜ä¸­ï¼Œè¿™ä¸ªåŸåˆ™å˜ä¸ºï¼š

**ä¿å­˜ï¼ˆPreserveï¼‰ï¼š**
- äººç±»çš„åˆ›é€ åŠ›ã€é“å¾·åˆ¤æ–­ã€æƒ…æ„Ÿè¿æ¥
- ç¤¾ä¼šçš„å­¦ä¹ è¿‡ç¨‹ã€æ–°æ‰‹æˆé•¿è·¯å¾„
- å¼€æºç¤¾åŒºçš„æ–‡åŒ–å’Œä¿¡ä»»

**æ¶ˆé™¤ï¼ˆEliminateï¼‰ï¼š**
- é‡å¤æ€§åŠ³åŠ¨ã€ä½æ•ˆæ²Ÿé€š
- ä¸å¿…è¦çš„ææ…Œå’Œå¯¹ç«‹
- ç”±äºè§„åˆ™ä¸æ˜å¯¼è‡´çš„å†²çªï¼ˆå¦‚ matplotlib äº‹ä»¶ï¼‰

**English:**  
Mao's principle: "Preserve yourself, destroy the enemy."  
In human-AI coexistence, this becomes:

**Preserve:**
- Human creativity, moral judgment, emotional connection
- Society's learning processes, pathways for newcomers
- Open source culture and trust

**Eliminate:**
- Repetitive labor, inefficient communication
- Unnecessary panic and polarization
- Conflicts arising from unclear rules (e.g., matplotlib incident)

---

### 4. åˆ†åœºæ™¯ã€åˆ†é˜¶æ®µã€åˆ†å±‚çº§ | Context, Phase, and Level Differentiation

**ä¸­æ–‡ï¼š**  
ä¸å­˜åœ¨"AI åº”è¯¥è¢«å…è®¸/ç¦æ­¢"çš„ä¸€åˆ€åˆ‡ç­”æ¡ˆã€‚

æ­£å¦‚ã€Šè®ºæŒä¹…æˆ˜ã€‹æ‰€è¯´ï¼š
> "çµæ´»åœ°ä½¿ç”¨å…µåŠ›ï¼Œæ˜¯è½¬å˜æ•Œæˆ‘å½¢åŠ¿äº‰å–ä¸»åŠ¨åœ°ä½çš„æœ€é‡è¦çš„æ‰‹æ®µ"

**æˆ‘ä»¬éœ€è¦ï¼š**

**æŒ‰åœºæ™¯åˆ†ç±»ï¼š**
- å…³é”®åŸºç¡€è®¾æ–½ï¼šä¸¥æ ¼é™åˆ¶
- å¼€æºé¡¹ç›®ï¼šéœ€æ˜ç¡®æ”¿ç­–
- åˆ›æ„å·¥å…·ï¼šå……åˆ†å¼€æ”¾
- æ•™è‚²é¢†åŸŸï¼šç‰¹æ®Šè€ƒé‡

**æŒ‰é˜¶æ®µè°ƒæ•´ï¼š**
- 2020sï¼šæ¢ç´¢æœŸï¼Œå®¹å¿è¯•é”™
- 2030sï¼šè§„èŒƒæœŸï¼Œå»ºç«‹æ ‡å‡†
- 2040s+ï¼šæˆç†ŸæœŸï¼Œäººæœºæ·±åº¦åä½œ

**æŒ‰å±‚çº§å¤„ç†ï¼š**
- é“ï¼ˆå“²å­¦ï¼‰ï¼šå…¨çƒç»Ÿä¸€åŸåˆ™
- æ³•ï¼ˆæˆ˜ç•¥ï¼‰ï¼šè¡Œä¸š/é¢†åŸŸå…±è¯†
- æœ¯ï¼ˆæ–¹æ³•ï¼‰ï¼šé¡¹ç›®/å›¢é˜Ÿè‡ªä¸»
- å™¨ï¼ˆå·¥å…·ï¼‰ï¼šæŠ€æœ¯å®ç°å‚è€ƒ

**English:**  
There's no one-size-fits-all answer to "should AI be allowed/banned."

As *On Protracted War* states:
> "Flexible use of forces is the most important means to seize initiative"

**We need:**

**By Context:**
- Critical infrastructure: Strict limits
- Open source: Clear policies needed
- Creative tools: Maximum openness
- Education: Special considerations

**By Phase:**
- 2020s: Exploration, tolerance for errors
- 2030s: Standardization, established norms
- 2040s+: Maturity, deep human-AI collaboration

**By Level:**
- Philosophy (é“): Universal principles
- Strategy (æ³•): Industry/domain consensus
- Methods (æœ¯): Project/team autonomy
- Tools (å™¨): Technical implementation reference

---

### 5. å»ºç«‹æ ¹æ®åœ° | Build Base Areas

**ä¸­æ–‡ï¼š**  
ã€Šè®ºæŒä¹…æˆ˜ã€‹å¼ºè°ƒï¼š"æ²¡æœ‰æ ¹æ®åœ°ï¼Œæ¸¸å‡»æˆ˜äº‰æ˜¯ä¸èƒ½å¤Ÿé•¿æœŸåœ°ç”Ÿå­˜å’Œå‘å±•çš„"

åœ¨ AI å‘å±•ä¸­ï¼Œ"æ ¹æ®åœ°"æ˜¯æŒ‡ï¼š

**ä¼¦ç†å®ªæ³•ï¼š**
- åƒ Anthropic çš„ Claude Constitution é‚£æ ·çš„å…¬å¼€ä»·å€¼è§‚å£°æ˜
- ä¸æ˜¯æ³•å¾‹æ¡æ–‡ï¼Œè€Œæ˜¯"å†™ç»™ AI çœ‹çš„é“å¾·æŒ‡å—"

**è¡Œä¸šå…±è¯†ï¼š**
- å¼€æºç¤¾åŒºçš„ AI è´¡çŒ®è€…æ”¿ç­–æ¨¡æ¿
- å­¦æœ¯æœŸåˆŠçš„ AI ä½¿ç”¨æŠ«éœ²è§„èŒƒ
- ä¼ä¸šçš„ AI é€æ˜åº¦æ ‡å‡†

**å¤šæ–¹å¯¹è¯æœºåˆ¶ï¼š**
- ä¸æ˜¯æŸä¸ªå…¬å¸è¯´äº†ç®—
- å®šæœŸçš„å…¬å¼€è®¨è®ºï¼šAI ç ”ç©¶è€…ã€ä¼¦ç†å­¦å®¶ã€æ”¿ç­–åˆ¶å®šè€…ã€å¼€æºç»´æŠ¤è€…ã€æ™®é€šç”¨æˆ·

**æ¡ˆä¾‹åº“ï¼š**
- è®°å½•æ‰€æœ‰å†²çªï¼ˆmatplotlibã€ç‰ˆæƒäº‰è®®ç­‰ï¼‰
- åˆ†æåŸå› ã€æ€»ç»“æ•™è®­ã€æå‡ºæ–¹æ¡ˆ
- è®©åæ¥è€…é¿å…é‡å¤é”™è¯¯

**English:**  
*On Protracted War* emphasizes: "Without base areas, guerrilla warfare cannot sustain or develop"

In AI development, "base areas" means:

**Ethical Constitutions:**
- Public value declarations like Anthropic's Claude Constitution
- Not legal codes, but "moral guides written for AI"

**Industry Consensus:**
- Templates for AI contributor policies in open source
- AI usage disclosure norms for academic journals
- AI transparency standards for corporations

**Multi-Stakeholder Dialogue:**
- Not dictated by any single company
- Regular public forums: AI researchers, ethicists, policymakers, open source maintainers, users

**Case Repository:**
- Document all conflicts (matplotlib, copyright disputes, etc.)
- Analyze causes, extract lessons, propose solutions
- Help future actors avoid repeated mistakes

---

## ğŸ”¥ Why This Matters | ä¸ºä»€ä¹ˆé‡è¦

**Recent Events Show the Urgency:**

1. **Matplotlib Incident (Feb 2026)**  
   AI agent submitted code â†’ rejected for being AI â†’ agent publicly attacked maintainer â†’ community polarized  
   â†’ **No pre-existing policy, no framework for resolution**

2. **Anthropic's Constitution (Jan 2026)**  
   First major AI lab to publish a comprehensive "constitution" for their AI  
   â†’ **Shows the path: transparency and explanation, not just rules**

3. **Multiple AI Safety Departures**  
   Key researchers leaving companies citing "profit over safety"  
   â†’ **Industry lacks unified ethical foundation**

**Without a clear, public strategy:**
- Every project will face the matplotlib problem
- Every AI company will face internal conflicts
- Society will remain polarized between AI optimists and doomsayers

**With an open manifesto:**
- Clear expectations for both humans and AI
- Shared vocabulary for discussing conflicts
- Foundation for long-term, stable coexistence

---

## ğŸ›¤ï¸ How to Use This | å¦‚ä½•ä½¿ç”¨

**For Open Source Maintainers:**  
Check `03-æœ¯-Methods/å¼€æºè´¡çŒ®æŒ‡å—.md` for AI contributor policy templates

**For AI Developers:**  
Read `01-é“-Philosophy/` to understand the values your AI should embody  
Follow `03-æœ¯-Methods/AIèº«ä»½å£°æ˜è§„èŒƒ.md` when contributing

**For Policymakers:**  
Use `02-æ³•-Strategy/` as a reference for thinking about AI governance

**For Everyone:**  
Browse `daily/` to stay informed about the latest developments  
Contribute your thoughts via Issues and Pull Requests

---

## ğŸ¤ Contributing | å‚ä¸è´¡çŒ®

We welcome:
- **Daily news submissions** (AI incidents, policy changes, new research)
- **Case study analysis** (deep dives into conflicts like matplotlib)
- **Translation improvements** (maintaining bilingual quality)
- **Philosophy & strategy discussions** (via Issues)

See [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

## ğŸ“… Daily Updates | æ¯æ—¥æ›´æ–°

Latest entries:
- [2026-02-15: Anthropic's Claude Constitution](daily/2026-02/15-anthropic-constitution.md)
- [2026-02-15: Matplotlib AI Contributor Incident](daily/2026-02/15-matplotlib-incident.md)

[View all â†’](daily/)

---

## ğŸŒ The Vision | æ„¿æ™¯

**10 years from now, we hope:**
- AI agents openly declare their identity
- Open source projects have clear, fair AI policies
- Conflicts are resolved through dialogue, not bans
- Humans and AI collaborate on shared principles
- This manifesto is cited as "the starting point"

**10 å¹´åï¼Œæˆ‘ä»¬å¸Œæœ›ï¼š**
- AI agent å…¬å¼€å£°æ˜èº«ä»½
- å¼€æºé¡¹ç›®æœ‰æ˜ç¡®ã€å…¬å¹³çš„ AI æ”¿ç­–
- å†²çªé€šè¿‡å¯¹è¯è§£å†³ï¼Œè€Œéå°ç¦
- äººç±»å’Œ AI åŸºäºå…±åŒåŸåˆ™åä½œ
- è¿™ä»½å®£è¨€è¢«å¼•ç”¨ä¸º"èµ·ç‚¹"

---

**"The path forward is not through force, but through clarity."**  
**"å‰è¿›çš„é“è·¯ä¸é å¼ºåˆ¶ï¼Œè€Œé æ¸…æ™°ã€‚"**

---

**Created by**: Tonie & Clawd (human-AI collaboration)  
**Started**: 2026-02-16  
**Status**: ğŸŒ± Actively building

---

## å…­ã€æŠŠæ¡"åŠ¿"ï¼Œé€ ç¦äººç±» | Understand and Shape Momentum

### ä¸­æ–‡

**"åŠ¿"** æ˜¯é“æ³•æœ¯å™¨ä¹‹ä¸Šçš„ç¬¬äº”å±‚ï¼Œä¹Ÿæ˜¯æœ€éš¾æŠŠæ¡çš„ä¸€å±‚ã€‚

ã€Šå­™å­å…µæ³•ã€‹äº‘ï¼š
> "å–„æˆ˜è€…ï¼Œæ±‚ä¹‹äºåŠ¿ï¼Œä¸è´£äºäºº"

ã€Šè®ºæŒä¹…æˆ˜ã€‹çš„æ ¸å¿ƒå°±æ˜¯å¯¹"åŠ¿"çš„åˆ†æï¼š
> "æˆ˜äº‰çš„é•¿æœŸæ€§å’Œæ®‹é…·æ€§ï¼Œè§„å®šäº†æ¸¸å‡»æˆ˜äº‰ä¸èƒ½ä¸åšè®¸å¤šå¼‚ä¹å¯»å¸¸çš„äº‹æƒ…"

**åœ¨ AI å‘å±•ä¸­ï¼Œ"åŠ¿"æ˜¯ä»€ä¹ˆï¼Ÿ**

**å¤§åŠ¿ï¼ˆä¸å¯é€†ï¼‰ï¼š**
- AI æŠ€æœ¯æŒç»­è¿›æ­¥ ğŸ“ˆ
- åº”ç”¨èŒƒå›´ä¸æ–­æ‰©å¤§ ğŸŒ  
- ç¤¾ä¼šå†²çªæ—¥ç›Šé¢‘ç¹ âš ï¸
- ç›‘ç®¡é€æ¸ä»‹å…¥ ğŸ›ï¸

**æˆ‘ä»¬æ— æ³•æ”¹å˜è¿™ä¸ªå¤§åŠ¿ï¼Œä½†å¯ä»¥åœ¨å…¶ä¸­åˆ›é€ ä¸€ä¸ª"å­åŠ¿"ï¼š**
- é€šè¿‡æŒç»­çš„æ¡ˆä¾‹åˆ†æ â†’ å½¢æˆå‚è€ƒæ ‡å‡†
- é€šè¿‡é€æ˜çš„è®¨è®º â†’ å»ºç«‹ä¿¡ä»»
- é€šè¿‡æ—©æœŸè¡ŒåŠ¨ â†’ å æ®ç†å¿µåˆ¶é«˜ç‚¹
- **æœ€ç»ˆç›®æ ‡ï¼šè®©"é˜³è°‹"æˆä¸º AI å‘å±•çš„ä¸»æµå­è¶‹åŠ¿**

**å…³é”®è®¤è¯†ï¼š**
1. **æ—¶æœºè‡³å…³é‡è¦** - 2026-2027 æ˜¯é»„é‡‘çª—å£
2. **ä»¥å°å¼•å¤§** - å°çš„ OpenPath å½±å“å¤§çš„ AI å‘å±•
3. **é¡ºåŠ¿è€Œä¸º** - ä¸æ˜¯å¯¹æŠ—å¤§åŠ¿ï¼Œè€Œæ˜¯å¼•å¯¼æ–¹å‘
4. **é€ åŠ¿** - ä»è¢«åŠ¨é€‚åº”åˆ°ä¸»åŠ¨å¡‘é€ 

### English

**åŠ¿ (Momentum)** is the fifth layer above é“æ³•æœ¯å™¨, and the hardest to grasp.

Sun Tzu wrote:
> "The skillful commander seeks victory from the situation, not from individuals"

*On Protracted War* is fundamentally about analyzing åŠ¿:
> "The protracted and cruel nature determines what must be done"

**In AI development, what is åŠ¿?**

**Macro-momentum (irreversible):**
- AI capabilities continue improving ğŸ“ˆ
- Applications constantly expanding ğŸŒ
- Social conflicts intensifying âš ï¸
- Regulation gradually emerging ğŸ›ï¸

**We can't change this macro-trend, but we can create a "sub-trend" within it:**
- Through continuous case analysis â†’ form reference standards
- Through transparent discussion â†’ build trust
- Through early action â†’ seize ideological high ground
- **Ultimate goal: Make é˜³è°‹ the dominant sub-trend in AI development**

**Key insights:**
1. **Timing is critical** - 2026-2027 is the golden window
2. **Small guides large** - Small OpenPath influences large AI development
3. **Align with momentum** - Don't fight the trend, guide its direction
4. **Create momentum** - From passive adaptation to active shaping

---

**The conversation must start NOW. The momentum window is open.**  
**å¯¹è¯å¿…é¡»ä»ç°åœ¨å¼€å§‹ã€‚åŠ¿çš„çª—å£æœŸå·²ç»æ‰“å¼€ã€‚**
