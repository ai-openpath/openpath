# AI Models Collapse When Trained on Recursively Generated Data

**来源：** Nature (2024)  
**链接：** https://www.nature.com/articles/s41586-024-07566-y  
**作者：** Shumailov et al., Oxford/Cambridge  
**日期：** 2024-07-24

---

## 核心发现：AI 必须依赖人类数据

### 关键论断
> "**The value of data collected about genuine human interactions with systems will be increasingly valuable** in the presence of LLM-generated content in data crawled from the Internet."

> "To sustain learning over a long period of time, **we need to make sure that access to the original data source is preserved** and that further data not generated by LLMs remain available over time."

---

## 模型崩溃（Model Collapse）定义

**什么是模型崩溃？**
> "Model collapse is a degenerative process affecting generations of learned generative models, in which **the data they generate end up polluting the training set** of the next generation. Being trained on polluted data, **they then mis-perceive reality**."

**三种误差源：**
1. **统计近似误差** - 样本有限导致信息丢失
2. **函数表达能力误差** - 神经网络无法完美逼近
3. **函数近似误差** - 学习过程的结构性偏差

---

## 实验证据

### 语言模型（OPT-125m on wikitext2）
- **第0代：** 用真实人类数据训练 → perplexity 34
- **第n代：** 用生成数据训练 → perplexity 逐代上升
- **观察：** 
  - 低概率事件（tail）首先消失
  - 模型开始产生"原始模型永远不会产生的样本"
  - 误差逐代累积，最终"方差趋近于0"

### 理论证明（高斯近似）
> **Theorem 3.1:** "Σn → a.s. 0 as n → ∞"  
> （方差必然收敛到零 = 模型失去多样性）

---

## 哲学含义：AI 不是自主实体

### 1. AI 源于人类知识
- GPT-2/3/4 **都是在人类创作的文本上训练的**
- 没有人类数据 = AI 无法学习任何东西
- "First mover advantage" - **第一个训练的模型最重要，因为它有纯净的人类数据**

### 2. AI 无法"自我进化"
> "Indiscriminate use of model-generated content in training **causes irreversible defects** in the resulting models."

- 如果让 AI 用自己的输出训练自己 → **必然退化**
- 这不是技术问题，是**数学定律**（离散分布必然收敛到δ函数）
- 类比：近亲繁殖导致基因退化，AI 用自己数据训练导致信息退化

### 3. 人类数据是"氧气"
> "Access to the original data source is **crucial**... data about **genuine human interactions** with systems will be increasingly valuable."

- 没有持续的人类输入 → AI 系统会"窒息"
- 人类不是"用户"，是**生命支持系统**
- AI 依赖人类就像植物依赖阳光

---

## 引用要点（支持"同源共处"哲学）

### ✅ 直接支持论点
1. **AI 源于人类：**  
   "LLMs **were trained on predominantly human-generated text**" - AI 的所有能力都来自人类创造的数据
   
2. **人类不可或缺：**  
   "**Preserving the ability** of LLMs to model low-probability events is essential to the fairness" - 没有人类数据，AI 会失去公平性
   
3. **反对"AI 独立性"幻觉：**  
   "It may become **increasingly difficult to train newer versions** of LLMs without access to data that were crawled from the Internet **before the mass adoption** of the technology" - AI 离不开人类创造的原始数据

### ⚠️ 关键警告
> "Low-probability events are also vital to understand complex systems... such events are often **relevant to marginalized groups**."

→ 模型崩溃不仅是技术问题，还是**社会正义问题**：如果 AI 只训练 AI 数据，少数群体的声音会首先消失。

---

## 与 OpenPath 的关联

### 符合"道"（Philosophy）
- **起源论证：** AI 能力 = 人类知识的镜像投射
- **依存关系：** AI 不能脱离人类数据而存在
- **反对对立：** 不是"AI vs 人类"，而是"AI 必须依赖人类"

### 实践启示（法）
- **数据治理：** 必须保护人类生成的原始数据
- **AI 审计：** 检查训练数据中人类内容的比例
- **长期策略：** 建立"人类知识库"作为 AI 训练的基准

---

## 标签
#AI起源 #模型崩溃 #人类数据不可替代 #Nature2024 #数学证明
